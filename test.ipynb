{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9da80ce-8481-4cac-8eb3-6d0ac6954636",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelWithLMHead, SummarizationPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00f29392-6d6d-4fdc-987f-2ae722aa0abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704192941c3646b497dedac67440bfd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/645 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1a5a2f3a51a485b97d1d92bd34ef82c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.95G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54964993809f4b54af34673c347035dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/797k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0523215ff0ac446fb88c85f782a37fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.79k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf51e48de1a43bd9f4fc41c6f506ae4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/24.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline = SummarizationPipeline(\n",
    "    model=AutoModelWithLMHead.from_pretrained(\"SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask_finetune\"),\n",
    "    tokenizer=AutoTokenizer.from_pretrained(\"SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask_finetune\", skip_special_tokens=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f49da58e-54f1-464e-a9d6-c106ad7ec901",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 20, but you input_length is only 14. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Find the maximum value in values'"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_code = \"\"\"\n",
    "def find_max(values):\\n    return max(values)\n",
    "\"\"\"\n",
    "pipeline([tokenized_code])[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9e0ac278-b29c-417a-bf5f-17906f8cfd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('test-file.py', 'r')\n",
    "file = f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4886cbc-db3d-4fa0-a1af-7177e3f6fb8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"import newspaper\\n\\n\\ndef find_max(values):\\n    return max(values)\\n\\n\\ndef average(values: list) -> int:\\n\\n    total = 0\\n    for i in values:\\n        total += i\\n\\n    return total/len(values)\\n\\n\\ndef chunks(l, n):\\n    d, r = divmod(len(l), n)\\n    for i in range(n):\\n        si = (d + 1) * (i if i < r else r) + d * (0 if i < r else i - r)\\n        yield l[si:si + (d + 1 if i < r else d)]\\n\\n\\ndef pull_articles_from_source(url, source, article_data=[]):\\n    paper = newspaper.build(url)\\n    i = 0\\n    failed = 0\\n    print(len(paper.articles))\\n    paper.download_articles()\\n    paper.parse_articles()  # remove articles that are too small (probably not articles)\\n    print(len(paper.articles))\\n    for article in paper.articles:\\n        i += 1\\n        if i > 10:\\n            break\\n        try:\\n            # fail if the article is empty or less than 40 words\\n            if article.text.isspace() or article.text == '' or len(article.text.split(' ')) < 40:\\n                failed += 1\\n                continue\\n            article.nlp()\\n\\n            authors = article.authors\\n            temp = []\\n            for i in authors:\\n                if len(i.split(' ')) > 5:\\n                    continue\\n                temp.append(i)\\n            authors = temp\\n\\n            data = {'source': source, 'title': article.title, 'authors': authors, 'text': article.text,\\n                    'keywords': article.keywords, 'summary': article.summary, 'url': article.url,\\n                    'date': article.publish_date}\\n            article_data.append(data)\\n        except:\\n            failed += 1\\n\\n    return article_data\\n\\n\\ndef source_from_url(link):\\n\\n    if 'www' in link:\\n        source = link.split('.')[1]\\n    else:\\n        if '.com' in link:\\n            source = link.split('.com')[0]\\n        else:\\n            source = link.split('.')[0]\\n    source = source.replace('https://', '')\\n    source = source.replace('http://', '')\\n    return source\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1e90a885-45e3-4ce8-868c-2d27e61fd811",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pull_out_top_function(file):\n",
    "    # find first def\n",
    "    index = file.find('def ') # won't work if something ends in def like a variable\n",
    "    if index == -1:\n",
    "        return None\n",
    "\n",
    "    # then grab all of the following text until there is no space between a newline character and the next character (signifiying the first code outside the function)\n",
    "    sub_file = file[index:]\n",
    "    for i in range(len(sub_file)-1):\n",
    "        # you don't look for return statements because there can be more than one\n",
    "        if sub_file[i] == '\\n' and  not sub_file[i+1].isspace():\n",
    "            return sub_file[:i]\n",
    "        \n",
    "    # def was found but \n",
    "    return sub_file.strip()\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7ce5dce5-1b41-4ad7-b777-eba2fe651ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'def find_max(values):\\n    return max(values)\\n\\n'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pull_out_top_function(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3df72789-1c36-453a-97c7-a3d7fb4bf43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_file = file\n",
    "new_file = file\n",
    "\n",
    "while 'def ' in sub_file:\n",
    "\n",
    "    function = pull_out_top_function(sub_file)\n",
    "\n",
    "    original_function = function\n",
    "    summary = 'this is the summary'\n",
    "\n",
    "    # TODO won't work for functions within classes or things that need more spaces\n",
    "    # need to find a way to dynamically get the correct spacing\n",
    "    function = function.replace(':\\n', f':\\n    \"\"\"\\n    {summary}\\n    \"\"\"\\n', 1)  # TODO this won't work for the case where theres a lot of type hints in the function definition and theres a ':\\n'\n",
    "    \n",
    "    new_file = new_file.replace(original_function, function)\n",
    "    \n",
    "    sub_file = file[file.find(original_function) + len(original_function):]  # grab the rest of the file after the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "9a4d49ff-9e52-4770-bcc9-7689b21d74d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import newspaper\n",
      "\n",
      "\n",
      "def find_max(values):\n",
      "    \"\"\"\n",
      "    this is the summary\n",
      "    \"\"\"\n",
      "    return max(values)\n",
      "\n",
      "\n",
      "def average(values: list) -> int:\n",
      "    \"\"\"\n",
      "    this is the summary\n",
      "    \"\"\"\n",
      "\n",
      "    total = 0\n",
      "    for i in values:\n",
      "        total += i\n",
      "\n",
      "    return total/len(values)\n",
      "\n",
      "\n",
      "def chunks(l, n):\n",
      "    \"\"\"\n",
      "    this is the summary\n",
      "    \"\"\"\n",
      "    d, r = divmod(len(l), n)\n",
      "    for i in range(n):\n",
      "        si = (d + 1) * (i if i < r else r) + d * (0 if i < r else i - r)\n",
      "        yield l[si:si + (d + 1 if i < r else d)]\n",
      "\n",
      "\n",
      "def pull_articles_from_source(url, source, article_data=[]):\n",
      "    \"\"\"\n",
      "    this is the summary\n",
      "    \"\"\"\n",
      "    paper = newspaper.build(url)\n",
      "    i = 0\n",
      "    failed = 0\n",
      "    print(len(paper.articles))\n",
      "    paper.download_articles()\n",
      "    paper.parse_articles()  # remove articles that are too small (probably not articles)\n",
      "    print(len(paper.articles))\n",
      "    for article in paper.articles:\n",
      "        i += 1\n",
      "        if i > 10:\n",
      "            break\n",
      "        try:\n",
      "            # fail if the article is empty or less than 40 words\n",
      "            if article.text.isspace() or article.text == '' or len(article.text.split(' ')) < 40:\n",
      "                failed += 1\n",
      "                continue\n",
      "            article.nlp()\n",
      "\n",
      "            authors = article.authors\n",
      "            temp = []\n",
      "            for i in authors:\n",
      "                if len(i.split(' ')) > 5:\n",
      "                    continue\n",
      "                temp.append(i)\n",
      "            authors = temp\n",
      "\n",
      "            data = {'source': source, 'title': article.title, 'authors': authors, 'text': article.text,\n",
      "                    'keywords': article.keywords, 'summary': article.summary, 'url': article.url,\n",
      "                    'date': article.publish_date}\n",
      "            article_data.append(data)\n",
      "        except:\n",
      "            failed += 1\n",
      "\n",
      "    return article_data\n",
      "\n",
      "\n",
      "def source_from_url(link):\n",
      "    \"\"\"\n",
      "    this is the summary\n",
      "    \"\"\"\n",
      "\n",
      "    if 'www' in link:\n",
      "        source = link.split('.')[1]\n",
      "    else:\n",
      "        if '.com' in link:\n",
      "            source = link.split('.com')[0]\n",
      "        else:\n",
      "            source = link.split('.')[0]\n",
      "    source = source.replace('https://', '')\n",
      "    source = source.replace('http://', '')\n",
      "    return source\n"
     ]
    }
   ],
   "source": [
    "print(new_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a99d62a6-e218-4d4c-aac6-3cb3cc4d0165",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
